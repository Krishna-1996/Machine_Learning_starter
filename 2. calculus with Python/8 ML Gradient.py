# 8. ML Gradient:
'''
--> Partial Derivative of Multi variant Function
--> Partial Derivative Chain Rule
--> Quadratic Cost
--> Gradients
--> Gradient Descent
--> Back-Propagation
'''
# 1. Partial Derivative of Multi variant Function
#Single Regression
'''
z = (x^2 - y^2)
Let's y = zero(constant)
Then, 
==> z = x^2 - 0 #partial derivation of 'z' w.r.t to 'x'.
==> dz/dx = 2x
'''
import numpy as np
import matplotlib.pyplot as plt
import torch
import math
print("Equation ==> z = (x^2 - y^2)")
xs = np.linespace(-3, 3, 1000)


























